{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the random seed for reproducibility\n",
    "def set_random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# Load the dataset from the provided path and create a sparse matrix\n",
    "def load_data_sparse(file_path):\n",
    "    try:\n",
    "        # Load raw data\n",
    "        data = np.load(file_path)\n",
    "        print(f\"Data loaded successfully from {file_path}\")\n",
    "        print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "        # Extract user IDs and movie IDs\n",
    "        user_ids = data[:, 0]\n",
    "        movie_ids = data[:, 1]\n",
    "\n",
    "        # Binary representation (1 for rated, 0 for not rated)\n",
    "        binary_ratings = np.ones(len(user_ids), dtype=np.int8)\n",
    "\n",
    "        # Create a sparse matrix\n",
    "        num_users = user_ids.max()\n",
    "        num_movies = movie_ids.max()\n",
    "        sparse_matrix = csr_matrix((binary_ratings, (movie_ids - 1, user_ids - 1)), shape=(num_movies, num_users))\n",
    "\n",
    "        return sparse_matrix\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the data or creating sparse matrix: {e}\")\n",
    "        return None\n",
    "    \n",
    "def LSH_Imp (sparse_matrix):\n",
    "    try:\n",
    "        # Create Permutation Matrix of \n",
    "        \n",
    "        PS = 120 #Permutation Size \n",
    "        mov_size = sparse_matrix.shape[0]\n",
    "        usr_size = sparse_matrix.shape[1]\n",
    "\n",
    "        #Create the Permutation Matrix with size 100 * Movies Number\n",
    "        Perm_matrix = np.array([np.random.permutation(mov_size) + 1 for _ in range(PS)]).T\n",
    "        print(f\"Perm_matrix shape: {Perm_matrix.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Initialize the signature matrix with zeros values\n",
    "        signature_matrix = np.zeros((PS, usr_size))\n",
    "\n",
    "        # Compute MinHash signatures\n",
    "        for perm_idx in range(PS):  # Iterate over permutations\n",
    "            # Current permutation of movie indices\n",
    "            perm_vector = Perm_matrix[:, perm_idx]  # 1-based indices\n",
    "\n",
    "            # Convert to 0-based indices\n",
    "            perm_vector = perm_vector - 1\n",
    "\n",
    "            # Reorder the sparse matrix rows based on the permutation\n",
    "            permuted_matrix = sparse_matrix[perm_vector, :]\n",
    "\n",
    "            # Get the index of the first non zero \n",
    "            first_nonzero_indices = np.argmax(permuted_matrix != 0, axis=0)+1\n",
    "\n",
    "            signature_matrix[perm_idx,] = first_nonzero_indices\n",
    "        \n",
    "\n",
    "            print(f\"Processed permutation {perm_idx + 1}/{PS}\")\n",
    "\n",
    "        print(\"MinHash signatures computed.\")\n",
    "        return signature_matrix\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the data or creating sparse matrix: {e}\")\n",
    "        return None\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from /Users/amrshata/Desktop/RES/user_movie_rating.npy\n",
      "Data shape: (65225506, 3)\n",
      "MinHash signature matrix shape: (17770, 103703)\n",
      "Perm_matrix shape: (17770, 120)\n",
      "Processed permutation 1/120\n",
      "Processed permutation 2/120\n",
      "Processed permutation 3/120\n",
      "Processed permutation 4/120\n",
      "Processed permutation 5/120\n",
      "Processed permutation 6/120\n",
      "Processed permutation 7/120\n",
      "Processed permutation 8/120\n",
      "Processed permutation 9/120\n",
      "Processed permutation 10/120\n",
      "Processed permutation 11/120\n",
      "Processed permutation 12/120\n",
      "Processed permutation 13/120\n",
      "Processed permutation 14/120\n",
      "Processed permutation 15/120\n",
      "Processed permutation 16/120\n",
      "Processed permutation 17/120\n",
      "Processed permutation 18/120\n",
      "Processed permutation 19/120\n",
      "Processed permutation 20/120\n",
      "Processed permutation 21/120\n",
      "Processed permutation 22/120\n",
      "Processed permutation 23/120\n",
      "Processed permutation 24/120\n",
      "Processed permutation 25/120\n",
      "Processed permutation 26/120\n",
      "Processed permutation 27/120\n",
      "Processed permutation 28/120\n",
      "Processed permutation 29/120\n",
      "Processed permutation 30/120\n",
      "Processed permutation 31/120\n",
      "Processed permutation 32/120\n",
      "Processed permutation 33/120\n",
      "Processed permutation 34/120\n",
      "Processed permutation 35/120\n",
      "Processed permutation 36/120\n",
      "Processed permutation 37/120\n",
      "Processed permutation 38/120\n",
      "Processed permutation 39/120\n",
      "Processed permutation 40/120\n",
      "Processed permutation 41/120\n",
      "Processed permutation 42/120\n",
      "Processed permutation 43/120\n",
      "Processed permutation 44/120\n",
      "Processed permutation 45/120\n",
      "Processed permutation 46/120\n",
      "Processed permutation 47/120\n",
      "Processed permutation 48/120\n",
      "Processed permutation 49/120\n",
      "Processed permutation 50/120\n",
      "Processed permutation 51/120\n",
      "Processed permutation 52/120\n",
      "Processed permutation 53/120\n",
      "Processed permutation 54/120\n",
      "Processed permutation 55/120\n",
      "Processed permutation 56/120\n",
      "Processed permutation 57/120\n",
      "Processed permutation 58/120\n",
      "Processed permutation 59/120\n",
      "Processed permutation 60/120\n",
      "Processed permutation 61/120\n",
      "Processed permutation 62/120\n",
      "Processed permutation 63/120\n",
      "Processed permutation 64/120\n",
      "Processed permutation 65/120\n",
      "Processed permutation 66/120\n",
      "Processed permutation 67/120\n",
      "Processed permutation 68/120\n",
      "Processed permutation 69/120\n",
      "Processed permutation 70/120\n",
      "Processed permutation 71/120\n",
      "Processed permutation 72/120\n",
      "Processed permutation 73/120\n",
      "Processed permutation 74/120\n",
      "Processed permutation 75/120\n",
      "Processed permutation 76/120\n",
      "Processed permutation 77/120\n",
      "Processed permutation 78/120\n",
      "Processed permutation 79/120\n",
      "Processed permutation 80/120\n",
      "Processed permutation 81/120\n",
      "Processed permutation 82/120\n",
      "Processed permutation 83/120\n",
      "Processed permutation 84/120\n",
      "Processed permutation 85/120\n",
      "Processed permutation 86/120\n",
      "Processed permutation 87/120\n",
      "Processed permutation 88/120\n",
      "Processed permutation 89/120\n",
      "Processed permutation 90/120\n",
      "Processed permutation 91/120\n",
      "Processed permutation 92/120\n",
      "Processed permutation 93/120\n",
      "Processed permutation 94/120\n",
      "Processed permutation 95/120\n",
      "Processed permutation 96/120\n",
      "Processed permutation 97/120\n",
      "Processed permutation 98/120\n",
      "Processed permutation 99/120\n",
      "Processed permutation 100/120\n",
      "Processed permutation 101/120\n",
      "Processed permutation 102/120\n",
      "Processed permutation 103/120\n",
      "Processed permutation 104/120\n",
      "Processed permutation 105/120\n",
      "Processed permutation 106/120\n",
      "Processed permutation 107/120\n",
      "Processed permutation 108/120\n",
      "Processed permutation 109/120\n",
      "Processed permutation 110/120\n",
      "Processed permutation 111/120\n",
      "Processed permutation 112/120\n",
      "Processed permutation 113/120\n",
      "Processed permutation 114/120\n",
      "Processed permutation 115/120\n",
      "Processed permutation 116/120\n",
      "Processed permutation 117/120\n",
      "Processed permutation 118/120\n",
      "Processed permutation 119/120\n",
      "Processed permutation 120/120\n",
      "MinHash signatures computed.\n",
      "MinHash signature matrix shape: (120, 103703)\n"
     ]
    }
   ],
   "source": [
    " # Load the user_movie_rating.npy file and convert to a sparse binary matrix\n",
    "sparse_matrix = load_data_sparse(\"/Users/amrshata/Desktop/RES/user_movie_rating.npy\")\n",
    "set_random_seed(42)\n",
    "\n",
    "print(f\"MinHash signature matrix shape: {sparse_matrix.shape}\")\n",
    "\n",
    "    # Compute MinHash signatures\n",
    "minhash_signatures = LSH_Imp(sparse_matrix)\n",
    "\n",
    "print(f\"MinHash signature matrix shape: {minhash_signatures.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_banding(signature_matrix, bands=10, rows_per_band=12):\n",
    "\n",
    "    try:\n",
    "        num_permutations, num_users = signature_matrix.shape  # Rows = num_permutations, Columns = num_users\n",
    "        candidate_pairs = set()  # Set to store unique candidate pairs (user1, user2)\n",
    "\n",
    "        # Iterate over each band\n",
    "        for band in range(bands):\n",
    "            start_row = band * rows_per_band  # Start index of the current band\n",
    "            end_row = start_row + rows_per_band  # End index of the current band\n",
    "\n",
    "            # Dictionary to store hashed buckets for the current band\n",
    "            band_hashes = {}\n",
    "\n",
    "            # Iterate over all users (columns in the signature matrix)\n",
    "            for user in range(num_users):\n",
    "                # Extract the mini-signature (rows belonging to this band) for the current user\n",
    "                band_signature = tuple(signature_matrix[start_row:end_row, user])\n",
    "                \n",
    "                # Hash the mini-signature to determine the bucket\n",
    "                bucket = hash(band_signature)\n",
    "\n",
    "                # Add the user to the corresponding bucket\n",
    "                if bucket in band_hashes:\n",
    "                    # If other users are already in the bucket, add pairs (user, candidate)\n",
    "                    for candidate in band_hashes[bucket]:\n",
    "                        # Ensure pairs are ordered as (min, max) to avoid duplicates\n",
    "                        candidate_pairs.add((min(user, candidate), max(user, candidate)))\n",
    "                    band_hashes[bucket].append(user)  # Add current user to the bucket\n",
    "                else:\n",
    "                    # Create a new bucket with the current user\n",
    "                    band_hashes[bucket] = [user]\n",
    "\n",
    "        # Print the total number of candidate pairs found\n",
    "        print(f\"Number of candidate pairs: {len(candidate_pairs)}\")\n",
    "        return candidate_pairs  # Return the set of candidate pairs\n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully\n",
    "        print(f\"Error in banding technique: {e}\")\n",
    "        return set()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of candidate pairs: 255134\n"
     ]
    }
   ],
   "source": [
    "candidate_pairs = apply_banding(minhash_signatures,14,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Jaccard Similarity\n",
    "def calculate_jaccard_similarity(sparse_matrix, candidate_pairs, threshold=0.5):\n",
    "\n",
    "    try:\n",
    "        similar_pairs = []  # List to store pairs with similarity above the threshold\n",
    "\n",
    "\n",
    "        sparse_matrix_csc = sparse_matrix.tocsc()\n",
    "\n",
    "        # Iterate over all candidate pairs\n",
    "        for u1, u2 in candidate_pairs:\n",
    "            # Retrieve the set of movies rated by user u1 and user u2\n",
    "            movies_u1 = set(sparse_matrix_csc[:, u1].indices)  # Indices of non-zero entries for user u1\n",
    "            movies_u2 = set(sparse_matrix_csc[:, u2].indices)  # Indices of non-zero entries for user u2\n",
    "\n",
    "            # Compute the intersection and union of the movie sets\n",
    "            intersection = len(movies_u1 & movies_u2)  # Number of common movies rated by both users\n",
    "            union = len(movies_u1 | movies_u2)         # Total number of unique movies rated by either user\n",
    "\n",
    "            # Calculate Jaccard Similarity\n",
    "            jaccard_similarity = intersection / union\n",
    "\n",
    "            # If similarity exceeds the threshold, add the pair to the result\n",
    "            if jaccard_similarity > threshold:\n",
    "                similar_pairs.append((u1 + 1, u2 + 1))  # Convert to 1-based indexing as required\n",
    "\n",
    "        # Print the total number of similar pairs found\n",
    "        print(f\"Number of similar pairs: {len(similar_pairs)}\")\n",
    "        return similar_pairs  # Return the list of similar pairs\n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully and return an empty list\n",
    "        print(f\"Error in Jaccard Similarity calculation: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of similar pairs: 67\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(52495, 99904),\n",
       " (9018, 16793),\n",
       " (46192, 47930),\n",
       " (77807, 101404),\n",
       " (82715, 83057),\n",
       " (50547, 101404),\n",
       " (27707, 81963),\n",
       " (43039, 53267),\n",
       " (25621, 49459),\n",
       " (14944, 30251),\n",
       " (64782, 97494),\n",
       " (15039, 18867),\n",
       " (8002, 29807),\n",
       " (35419, 53267),\n",
       " (9018, 75835),\n",
       " (9018, 68102),\n",
       " (489, 32557),\n",
       " (58328, 67675),\n",
       " (47930, 100079),\n",
       " (51237, 53267),\n",
       " (46365, 74191),\n",
       " (47930, 63974),\n",
       " (72733, 85467),\n",
       " (51237, 78973),\n",
       " (47930, 77807),\n",
       " (58328, 92016),\n",
       " (6545, 89023),\n",
       " (19153, 58328),\n",
       " (81963, 82715),\n",
       " (29807, 55105),\n",
       " (96810, 100079),\n",
       " (47930, 87445),\n",
       " (46528, 49457),\n",
       " (62898, 71374),\n",
       " (1324, 20164),\n",
       " (62898, 97494),\n",
       " (78517, 91158),\n",
       " (8002, 61934),\n",
       " (12896, 47930),\n",
       " (30525, 55033),\n",
       " (33367, 79725),\n",
       " (18867, 47930),\n",
       " (74191, 81963),\n",
       " (7849, 34194),\n",
       " (452, 9018),\n",
       " (15162, 47930),\n",
       " (28512, 58328),\n",
       " (48671, 95405),\n",
       " (12835, 18867),\n",
       " (30251, 72380),\n",
       " (47930, 93451),\n",
       " (66759, 98995),\n",
       " (47930, 91158),\n",
       " (35770, 85467),\n",
       " (9018, 58328),\n",
       " (3584, 58249),\n",
       " (9772, 55105),\n",
       " (74875, 79321),\n",
       " (33756, 75899),\n",
       " (74191, 88887),\n",
       " (4650, 9018),\n",
       " (91158, 100079),\n",
       " (63689, 91352),\n",
       " (53267, 85467),\n",
       " (37359, 53267),\n",
       " (11108, 58328),\n",
       " (61877, 74191)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Compute Jaccard Similarity for candidate pairs\n",
    "similar_pairs = calculate_jaccard_similarity(sparse_matrix, candidate_pairs)\n",
    "similar_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write results to a file\n",
    "def write_results(output_file, similar_pairs):\n",
    "    try:\n",
    "        with open(output_file, 'w') as f:\n",
    "            for u1, u2 in similar_pairs:\n",
    "                f.write(f\"{u1},{u2}\\n\")\n",
    "        print(f\"Results written to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing results to file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to /Users/amrshata/Desktop/RES/Data-Mining/output_file result.txt\n"
     ]
    }
   ],
   "source": [
    "    # Write results to the output file\n",
    "write_results(\"/Users/amrshata/Desktop/RES/Data-Mining/output_file result.txt\", similar_pairs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
